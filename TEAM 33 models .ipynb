{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Block 1: Environment Setup"
      ],
      "metadata": {
        "id": "XuDO0Nzeqs7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from google.colab import files\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "r4mtpoWHqspG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FILES UPPLOAD"
      ],
      "metadata": {
        "id": "59LHLRlhrKbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "required_files = ['hybrid_embeddings.npy', 'augmented.json', 'vocabulary.json']\n",
        "missing_files = [f for f in required_files if not os.path.exists(f)]\n",
        "if missing_files: uploaded = files.upload()"
      ],
      "metadata": {
        "id": "-Lcc5HjprAiW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LOAD DATA"
      ],
      "metadata": {
        "id": "8FC6R_X3rZhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.load('hybrid_embeddings.npy')\n",
        "with open(\"vocabulary.json\", \"r\") as f: word2idx = json.load(f)[\"word2idx\"]\n",
        "with open('augmented.json', 'r') as f: data = json.load(f)"
      ],
      "metadata": {
        "id": "F9gpsKHqrPL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PREPROCESS LABELS"
      ],
      "metadata": {
        "id": "lK264Npircf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_mapping = {-1: 0, 0: 1, 1: 2}\n",
        "labels = [label_mapping[sent['sentiment']] for sent in data]\n",
        "y = tf.keras.utils.to_categorical(labels, num_classes=3)"
      ],
      "metadata": {
        "id": "sNVdfvLYrgrJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PAD SEQUENCES"
      ],
      "metadata": {
        "id": "HqjwwbH2ros-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(sent['sentence']) for sent in data)\n",
        "padded_sequences = []\n",
        "for sent in data:\n",
        "    seq = [word2idx.get(word, 0) for word in sent['sentence']]\n",
        "    padded_sequences.append(seq[:max_len] + [0]*(max_len - len(seq)))\n",
        "X = np.array(padded_sequences)\n",
        "\n"
      ],
      "metadata": {
        "id": "TaN5sRilroVr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM LAYER"
      ],
      "metadata": {
        "id": "GXbBjwD7r2Eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EfficientLSTM(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.state_size = [units, units]\n",
        "        self.output_size = units\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units*4), initializer='glorot_uniform')\n",
        "        self.recurrent_kernel = self.add_weight(shape=(self.units, self.units*4), initializer='orthogonal')\n",
        "        self.bias = self.add_weight(shape=(self.units*4,), initializer='zeros')\n",
        "    def call(self, inputs, states):\n",
        "        h_prev, c_prev = states\n",
        "        z = tf.matmul(inputs, self.kernel) + tf.matmul(h_prev, self.recurrent_kernel) + self.bias\n",
        "        i, f, c_candidate, o = tf.split(z, 4, axis=1)\n",
        "        c = tf.sigmoid(f)*c_prev + tf.sigmoid(i)*tf.tanh(c_candidate)\n",
        "        h = tf.sigmoid(o) * tf.tanh(c)\n",
        "        return h, [h, c]"
      ],
      "metadata": {
        "id": "JuZAdpjlr1lW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Build Model"
      ],
      "metadata": {
        "id": "8XKGgP14r9pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_model():\n",
        "    inputs = tf.keras.Input(shape=(max_len,))\n",
        "    x = tf.keras.layers.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                weights=[embedding_matrix], mask_zero=True, trainable=False)(inputs)\n",
        "    x = tf.keras.layers.RNN(EfficientLSTM(64))(x)\n",
        "    outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.001, clipvalue=0.5),\n",
        "                loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "5-NcjzZCr9Ih"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TRAIN AND PREDICT"
      ],
      "metadata": {
        "id": "BVq9xLPUsSP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = create_model()\n",
        "history = model.fit(X, y, batch_size=128, epochs=50,\n",
        "                  validation_split=0.2, callbacks=[tf.keras.callbacks.EarlyStopping(patience=30)])\n",
        "\n",
        "\n",
        "def predict(sentence):\n",
        "    seq = [word2idx.get(word, 0) for word in sentence]\n",
        "    seq = seq[:max_len] + [0]*(max_len - len(seq))\n",
        "    proba = model.predict(np.array([seq]))[0]\n",
        "    return [\"Negative\", \"Neutral\", \"Positive\"][np.argmax(proba)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgQSJl3EsIRX",
        "outputId": "456a950f-6df6-46e9-be83-17705db45646"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 47ms/step - accuracy: 0.4788 - loss: 1.0258 - val_accuracy: 0.4248 - val_loss: 1.0438\n",
            "Epoch 2/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 43ms/step - accuracy: 0.5106 - loss: 0.9734 - val_accuracy: 0.4489 - val_loss: 1.0849\n",
            "Epoch 3/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.5234 - loss: 0.9493 - val_accuracy: 0.4970 - val_loss: 1.0159\n",
            "Epoch 4/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 45ms/step - accuracy: 0.5291 - loss: 0.9359 - val_accuracy: 0.4611 - val_loss: 1.0752\n",
            "Epoch 5/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 44ms/step - accuracy: 0.5342 - loss: 0.9234 - val_accuracy: 0.4834 - val_loss: 1.0556\n",
            "Epoch 6/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 44ms/step - accuracy: 0.5369 - loss: 0.9151 - val_accuracy: 0.5044 - val_loss: 1.0522\n",
            "Epoch 7/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 42ms/step - accuracy: 0.5449 - loss: 0.9058 - val_accuracy: 0.4978 - val_loss: 1.0698\n",
            "Epoch 8/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 42ms/step - accuracy: 0.5473 - loss: 0.8985 - val_accuracy: 0.4993 - val_loss: 1.0792\n",
            "Epoch 9/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.5489 - loss: 0.8921 - val_accuracy: 0.5062 - val_loss: 1.0681\n",
            "Epoch 10/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 44ms/step - accuracy: 0.5548 - loss: 0.8844 - val_accuracy: 0.4985 - val_loss: 1.1000\n",
            "Epoch 11/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 42ms/step - accuracy: 0.5538 - loss: 0.8799 - val_accuracy: 0.5191 - val_loss: 1.0726\n",
            "Epoch 12/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 42ms/step - accuracy: 0.5557 - loss: 0.8759 - val_accuracy: 0.5026 - val_loss: 1.1292\n",
            "Epoch 13/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.5596 - loss: 0.8683 - val_accuracy: 0.5036 - val_loss: 1.1392\n",
            "Epoch 14/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 45ms/step - accuracy: 0.5588 - loss: 0.8642 - val_accuracy: 0.5029 - val_loss: 1.1647\n",
            "Epoch 15/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 43ms/step - accuracy: 0.5657 - loss: 0.8559 - val_accuracy: 0.5213 - val_loss: 1.1410\n",
            "Epoch 16/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 45ms/step - accuracy: 0.5659 - loss: 0.8528 - val_accuracy: 0.5000 - val_loss: 1.1306\n",
            "Epoch 17/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 42ms/step - accuracy: 0.5681 - loss: 0.8463 - val_accuracy: 0.5023 - val_loss: 1.2097\n",
            "Epoch 18/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 45ms/step - accuracy: 0.5676 - loss: 0.8420 - val_accuracy: 0.4981 - val_loss: 1.1834\n",
            "Epoch 19/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 42ms/step - accuracy: 0.5742 - loss: 0.8367 - val_accuracy: 0.5240 - val_loss: 1.1763\n",
            "Epoch 20/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 45ms/step - accuracy: 0.5717 - loss: 0.8350 - val_accuracy: 0.5088 - val_loss: 1.2049\n",
            "Epoch 21/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 42ms/step - accuracy: 0.5760 - loss: 0.8288 - val_accuracy: 0.4968 - val_loss: 1.3007\n",
            "Epoch 22/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 45ms/step - accuracy: 0.5758 - loss: 0.8255 - val_accuracy: 0.4820 - val_loss: 1.2850\n",
            "Epoch 23/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 42ms/step - accuracy: 0.5760 - loss: 0.8237 - val_accuracy: 0.4917 - val_loss: 1.2892\n",
            "Epoch 24/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 42ms/step - accuracy: 0.5798 - loss: 0.8179 - val_accuracy: 0.5049 - val_loss: 1.2561\n",
            "Epoch 25/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 42ms/step - accuracy: 0.5797 - loss: 0.8152 - val_accuracy: 0.5232 - val_loss: 1.2437\n",
            "Epoch 26/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.5822 - loss: 0.8118 - val_accuracy: 0.4921 - val_loss: 1.3124\n",
            "Epoch 27/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 44ms/step - accuracy: 0.5848 - loss: 0.8077 - val_accuracy: 0.4926 - val_loss: 1.3100\n",
            "Epoch 28/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 45ms/step - accuracy: 0.5847 - loss: 0.8060 - val_accuracy: 0.4949 - val_loss: 1.3172\n",
            "Epoch 29/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 44ms/step - accuracy: 0.5876 - loss: 0.8017 - val_accuracy: 0.4791 - val_loss: 1.4345\n",
            "Epoch 30/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 42ms/step - accuracy: 0.5898 - loss: 0.7992 - val_accuracy: 0.4822 - val_loss: 1.4477\n",
            "Epoch 31/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.5866 - loss: 0.8018 - val_accuracy: 0.4795 - val_loss: 1.4338\n",
            "Epoch 32/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 42ms/step - accuracy: 0.5907 - loss: 0.7939 - val_accuracy: 0.4829 - val_loss: 1.4075\n",
            "Epoch 33/50\n",
            "\u001b[1m863/863\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 42ms/step - accuracy: 0.5879 - loss: 0.7953 - val_accuracy: 0.4924 - val_loss: 1.3935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "embedding_matrix = np.load('hybrid_embeddings.npy')\n",
        "with open(\"vocabulary.json\", \"r\") as f: word2idx = json.load(f)[\"word2idx\"]\n",
        "with open('augmented.json', 'r') as f: data = json.load(f)\n",
        "\n",
        "word_to_vec = {word: embedding_matrix[idx] for word, idx in word2idx.items() if idx < embedding_matrix.shape[0]}\n",
        "\n",
        "X = []\n",
        "for sent in data:\n",
        "    vecs = [word_to_vec[word] for word in sent['sentence'] if word in word_to_vec]\n",
        "    avg_vec = np.mean(vecs, axis=0) if vecs else np.zeros(embedding_matrix.shape[1])\n",
        "    X.append(avg_vec)\n",
        "X = np.array(X)\n",
        "\n",
        "label_mapping = {-1: 0, 0: 1, 1: 2}\n",
        "y = np.array([label_mapping[sent['sentiment']] for sent in data])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=200, max_depth=20, class_weight='balanced', n_jobs=-1, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negative (-1)', 'Neutral (0)', 'Positive (1)']))\n",
        "\n",
        "sample_sentence = data[0]['sentence']\n",
        "sample_vec = np.mean([word_to_vec[word] for word in sample_sentence if word in word_to_vec], axis=0)\n",
        "print(\"\\nSample Prediction:\", ['Negative', 'Neutral', 'Positive'][rf.predict([sample_vec])[0]])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdANj0cFDJUc",
        "outputId": "06aa1d3e-2c8e-4818-df5f-d7c09c2df2b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4830\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Negative (-1)       0.29      0.12      0.17      6553\n",
            "  Neutral (0)       0.44      0.60      0.51     11136\n",
            " Positive (1)       0.60      0.60      0.60      9926\n",
            "\n",
            "     accuracy                           0.48     27615\n",
            "    macro avg       0.44      0.44      0.42     27615\n",
            " weighted avg       0.46      0.48      0.46     27615\n",
            "\n",
            "\n",
            "Sample Prediction: Neutral\n"
          ]
        }
      ]
    }
  ]
}