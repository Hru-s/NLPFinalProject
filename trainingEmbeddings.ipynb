{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11460182,"sourceType":"datasetVersion","datasetId":7180916}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nimport numpy as np\nimport torch\nfrom pathlib import Path\n\n# Print versions and GPU info\nprint(f\"Python: {sys.version}\")\nprint(f\"NumPy: {np.__version__}\")\nprint(f\"Torch: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"GPU Devices: {torch.cuda.device_count()}\")\nif torch.cuda.is_available():\n    print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")","metadata":{"_uuid":"cf2bd444-2308-42a0-9f3d-59cdc34a7f13","_cell_guid":"714c500a-3f28-4529-85b2-3ef6bc1584c1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BASE_DIR = Path(\"/kaggle/working\")\nprint(f\"Working directory: {BASE_DIR}\")\n\n# Dataset directory (read-only, replace with actual folder name from sidebar)\nDATASET_NAME = \"data-for-nlp-major\"  # <-- CHANGE THIS\nDATA_DIR = Path(f\"/kaggle/input/{DATASET_NAME}\")\n\n# Checkpoint directory (writeable)\nCHECKPOINT_DIR = BASE_DIR / \"checkpoints\"\nCHECKPOINT_DIR.mkdir(exist_ok=True)\n\n# File paths\ndata_file = DATA_DIR / \"final.json\"\ncheckpoint_path = CHECKPOINT_DIR / \"w2v_checkpoint_gpu.npz\"\n\n# Output paths\nprint(f\"Data file: {data_file}\")\nprint(f\"Checkpoint path: {checkpoint_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_training_data(data, window_size=5):\n    pairs = []\n    for entry in data:\n        sentence = entry[\"sentence\"]\n        sentence_length = len(sentence)\n        for i, center in enumerate(sentence):\n            if center not in word2idx:\n                continue\n            for j in range(max(0, i - window_size), min(sentence_length, i + window_size + 1)):\n                if i != j and sentence[j] in word2idx:\n                    pairs.append((word2idx[center], word2idx[sentence[j]]))\n    return pairs\n\ntraining_pairs = generate_training_data(data, window_size=5)\nprint(f\"Number of training pairs: {len(training_pairs)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport os\n\nprint(\"Using device:\", torch.cuda.current_device())\n\n# --- Config ---\nembedding_dim = 100\nlearning_rate = 0.01\nnum_epochs = 30\nnegative_samples = 8\nbatch_size = 1024\n\nos.makedirs(CHECKPOINT_DIR, exist_ok=True)\n\n# --- Data ---\ntraining_pairs = torch.tensor(training_pairs, dtype=torch.int32)\nvocab_size = len(word2idx)\n\n# --- Load or initialize checkpoint ---\nstart_epoch = 0\nscale = 0.01\nif os.path.exists(checkpoint_path):\n    ckpt = torch.load(checkpoint_path)\n    W_in = ckpt[\"W_in\"].float()\n    W_out = ckpt[\"W_out\"].float()\n    start_epoch = int(ckpt[\"epoch\"])\n    # Load optimizer states\n    m_in = ckpt[\"m_in\"]\n    v_in = ckpt[\"v_in\"]\n    m_out = ckpt[\"m_out\"]\n    v_out = ckpt[\"v_out\"]\n    t_step = int(ckpt[\"t_step\"])\n    print(f\"Resumed from epoch {start_epoch}\")\n\n    if torch.isnan(W_in).any() or torch.isnan(W_out).any():\n        print(\"Checkpoint contains NaNs â€” resetting weights.\")\n        W_in = torch.FloatTensor(vocab_size, embedding_dim).uniform_(-scale, scale)\n        W_out = torch.FloatTensor(embedding_dim, vocab_size).uniform_(-scale, scale)\n        start_epoch = 0\nelse:\n    print(\"No checkpoint found. Initializing weights.\")\n    W_in = torch.FloatTensor(vocab_size, embedding_dim).uniform_(-scale, scale)\n    W_out = torch.FloatTensor(embedding_dim, vocab_size).uniform_(-scale, scale)\n    # Initialize optimizer states\n    m_in = torch.zeros_like(W_in)\n    v_in = torch.zeros_like(W_in)\n    m_out = torch.zeros_like(W_out)\n    v_out = torch.zeros_like(W_out)\n    t_step = 0\n\n# --- Adam Optimizer Hyperparameters ---\nbeta1 = 0.9\nbeta2 = 0.999\neps = 1e-8\n\n# --- Helper Functions ---\ndef sigmoid(x):\n    return 1 / (1 + torch.exp(-torch.clamp(x, -10, 10)))\n\ndef normalize_rows(mat):\n    norm = torch.norm(mat, dim=1, keepdim=True)\n    return mat / (norm + 1e-8)\n\n# Build unigram distribution\nword_freq = torch.tensor([word_counts[idx2word[i]] for i in range(vocab_size)], dtype=torch.float64)\nunigram_dist = word_freq ** 0.75\nunigram_dist /= unigram_dist.sum()\n\ndef get_negative_samples(batch_size, K):\n    return torch.multinomial(unigram_dist, num_samples=K, replacement=True)\n\n# --- Training Loop ---\nema_loss = None\nema_decay = 0.95\n\nfor epoch in range(start_epoch, num_epochs):\n    training_pairs = training_pairs[torch.randperm(training_pairs.size(0))]\n    total_loss = 0.0\n    num_batches = 0\n\n    for i in range(0, len(training_pairs), batch_size):\n        t_step += 1\n        batch = training_pairs[i:i + batch_size]\n        center_idxs = batch[:, 0]\n        target_idxs = batch[:, 1]\n\n        # Forward pass\n        v_c = W_in[center_idxs]\n        u_o = W_out[:, target_idxs]\n\n        # Positive samples\n        score_pos = torch.clamp(torch.sum(v_c * u_o.T, dim=1), -10, 10)\n        pred_pos = sigmoid(score_pos)\n\n        # Negative samples\n        neg_ids = get_negative_samples(len(center_idxs), negative_samples)\n        u_k = W_out[:, neg_ids.T].transpose(2, 1, 0)\n        score_neg = torch.clamp(torch.sum(v_c[:, None, :] * u_k, dim=2), -10, 10)\n        pred_neg = sigmoid(-score_neg)\n\n        # Loss calculation\n        pred_pos = torch.clamp(pred_pos, 1e-7, 1 - 1e-7)\n        pred_neg = torch.clamp(pred_neg, 1e-7, 1 - 1e-7)\n        loss = -torch.log(pred_pos).mean() - torch.log(pred_neg).mean()\n        total_loss += float(loss)\n        num_batches += 1\n\n        # Update EMA loss\n        ema_loss = loss if ema_loss is None else ema_decay * ema_loss + (1 - ema_decay) * loss\n\n        # --- W_in Gradients ---\n        grad_pos = (pred_pos - 1).reshape(-1, 1) * u_o.T\n        grad_neg = (1 - pred_neg)[:, :, None] * u_k\n        grad_in = grad_pos + grad_neg.mean(dim=1)\n        grad_in = torch.clamp(grad_in, -1, 1)  # Tighter clipping\n\n        # Adam update for W_in\n        m_in[center_idxs] = beta1 * m_in[center_idxs] + (1 - beta1) * grad_in\n        v_in[center_idxs] = beta2 * v_in[center_idxs] + (1 - beta2) * (grad_in ** 2)\n        m_hat = m_in[center_idxs] / (1 - beta1 ** t_step)\n        v_hat = v_in[center_idxs] / (1 - beta2 ** t_step)\n        W_in[center_idxs] -= learning_rate * m_hat / (torch.sqrt(v_hat) + eps)\n\n        # --- W_out Gradients (FIXED) ---\n        update_W_out = torch.zeros_like(W_out)\n        # Raw gradients without learning rate\n        update_W_out.scatter_add_(1, target_idxs.unsqueeze(0), (pred_pos - 1) * v_c.T)\n        for k in range(negative_samples):\n            update_W_out.scatter_add_(1, neg_ids[:, k].unsqueeze(0), grad_neg[:, k].T)\n\n        # Adam update for W_out\n        updated_cols = torch.unique(torch.cat((target_idxs, neg_ids.flatten())))\n        m_out[:, updated_cols] = beta1 * m_out[:, updated_cols] + (1 - beta1) * update_W_out[:, updated_cols]\n        v_out[:, updated_cols] = beta2 * v_out[:, updated_cols] + (1 - beta2) * (update_W_out[:, updated_cols] ** 2)\n        m_hat_out = m_out[:, updated_cols] / (1 - beta1 ** t_step)\n        v_hat_out = v_out[:, updated_cols] / (1 - beta2 ** t_step)\n        W_out[:, updated_cols] -= learning_rate * m_hat_out / (torch.sqrt(v_hat_out) + eps)\n\n    # End of epoch\n    avg_loss = total_loss / num_batches\n    grad_norm = torch.norm(grad_in, dim=1).mean()\n    print(f\"Epoch {epoch+1}, Avg Loss (EMA): {ema_loss:.4f}, Batch Avg Loss: {avg_loss:.4f}, Max Grad: {torch.max(torch.abs(grad_in)):.4f}, Grad Norm: {grad_norm:.4f}\")\n\n    # Save checkpoint with optimizer states\n    torch.save({\n        \"W_in\": W_in,\n        \"W_out\": W_out,\n        \"m_in\": m_in,\n        \"v_in\": v_in,\n        \"m_out\": m_out,\n        \"v_out\": v_out,\n        \"t_step\": t_step,\n        \"epoch\": epoch+1\n    }, checkpoint_path)\n\n    # Mild regularization\n    W_out = normalize_rows(W_out.T).T * 0.99 + W_out * 0.01\n\n    # NaN check\n    if torch.any(torch.isnan(W_in)) or torch.any(torch.isnan(W_out)):\n        print(\"NaN detected - reinitializing weights\")\n        W_in = torch.FloatTensor(vocab_size, embedding_dim).uniform_(-scale, scale)\n        W_out = torch.FloatTensor(embedding_dim, vocab_size).uniform_(-scale, scale)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}