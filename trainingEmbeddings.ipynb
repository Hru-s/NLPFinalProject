{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11584302,"sourceType":"datasetVersion","datasetId":7263349}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"cf2bd444-2308-42a0-9f3d-59cdc34a7f13","_cell_guid":"714c500a-3f28-4529-85b2-3ef6bc1584c1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\nimport numpy as np\nimport torch\nfrom pathlib import Path\n\n# Printing versions and GPU info\nprint(f\"Python: {sys.version}\")\nprint(f\"NumPy: {np.__version__}\")\nprint(f\"Torch: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"GPU Devices: {torch.cuda.device_count()}\")\nif torch.cuda.is_available():\n    print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")","metadata":{"_uuid":"cf2bd444-2308-42a0-9f3d-59cdc34a7f13","_cell_guid":"714c500a-3f28-4529-85b2-3ef6bc1584c1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-27T17:15:56.572530Z","iopub.execute_input":"2025-04-27T17:15:56.572855Z","iopub.status.idle":"2025-04-27T17:15:58.328340Z","shell.execute_reply.started":"2025-04-27T17:15:56.572829Z","shell.execute_reply":"2025-04-27T17:15:58.327541Z"}},"outputs":[{"name":"stdout","text":"Python: 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\nNumPy: 1.26.4\nTorch: 2.5.1+cu124\nCUDA available: True\nGPU Devices: 2\nCurrent GPU: Tesla T4\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"BASE_DIR = Path(\"/kaggle/working\")\nprint(f\"Working directory: {BASE_DIR}\")\n\nDATASET_NAME = \"data-for-nlp-major\"\nDATA_DIR = Path(f\"/kaggle/input/{DATASET_NAME}\")\n\nCHECKPOINT_DIR = BASE_DIR / \"checkpoints\"\nCHECKPOINT_DIR.mkdir(exist_ok=True)\n\ndata_file_1 = DATA_DIR / \"final_with_labels.json\"\ndata_file_2 = DATA_DIR / \"final_without_labels.json\"\ndata_file_3 = DATA_DIR / \"final_combined.json\"\ndata_file_4 = DATA_DIR / \"final_without_labels_2.json\"\ncheckpoint_path = CHECKPOINT_DIR / \"w2v_checkpoint_gpu.npz\"\n\nprint(f\"Data file 1: {data_file_1}\")\nprint(f\"Data file 2: {data_file_2}\")\nprint(f\"Data file 3: {data_file_3}\")\nprint(f\"Data file 4: {data_file_4}\")\nprint(f\"Checkpoint path: {checkpoint_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T17:15:58.329494Z","iopub.execute_input":"2025-04-27T17:15:58.329909Z","iopub.status.idle":"2025-04-27T17:15:58.336249Z","shell.execute_reply.started":"2025-04-27T17:15:58.329887Z","shell.execute_reply":"2025-04-27T17:15:58.335420Z"}},"outputs":[{"name":"stdout","text":"Working directory: /kaggle/working\nData file 1: /kaggle/input/data-for-nlp-major/final_with_labels.json\nData file 2: /kaggle/input/data-for-nlp-major/final_without_labels.json\nData file 3: /kaggle/input/data-for-nlp-major/final_combined.json\nData file 4: /kaggle/input/data-for-nlp-major/final_without_labels_2.json\nCheckpoint path: /kaggle/working/checkpoints/w2v_checkpoint_gpu.npz\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from collections import Counter\nimport json\nfrom pathlib import Path\nimport os\n\nprint(\"=== Vocabulary Builder ===\")\n\ntry:\n    def load_json(path):\n        with open(path, 'r', encoding='utf-8') as f:\n            arr = json.load(f)\n        if not isinstance(arr, list) or not arr:\n            raise ValueError(f\"{path.name} must be a non-empty list\")\n        if \"sentence\" not in arr[0]:\n            raise ValueError(f\"{path.name} entries require a sentence field\")\n        return arr\n\n    # Defining paths for vocab-building files\n    for path in (data_file_1, data_file_2, data_file_4):\n        if not path.exists():\n            raise FileNotFoundError(f\"Missing vocab source: {path}\")\n    \n    print(\"Loading data_file_1, data_file_2 and data_file_4...\")\n    data1 = load_json(data_file_1)\n    data2 = load_json(data_file_2)\n    data4 = load_json(data_file_4)\n\n    print(\"Processing sentences for vocab...\")\n    all_vocab_sentences = data1 + data2 + data4\n    words = [w for entry in all_vocab_sentences for w in entry[\"sentence\"]]\n    word_counts = Counter(words)\n    vocab = list(word_counts.keys())\n\n    word2idx = {w: i for i, w in enumerate(vocab)}\n    idx2word = {i: w for w, i in word2idx.items()}\n    vocab_size = len(vocab)\n\n    print(f\"\\nVocabulary built!\")\n    print(f\" Total tokens: {len(words):,}\")\n    print(f\" Unique words: {vocab_size:,}\")\n    print(f\" Top-5 frequent: {word_counts.most_common(5)}\")\n    print(\"\\nSample mappings:\")\n    for w in vocab[:10]:\n        print(f\"  '{w}': {word2idx[w]}\")\n\n    # saving vocabulary file\n    vocab_path = CHECKPOINT_DIR / \"vocabulary.json\"\n    with open(vocab_path, 'w', encoding='utf-8') as f:\n        json.dump({\"word2idx\": word2idx, \"idx2word\": idx2word},\n                  f, ensure_ascii=False, indent=2)\n    print(f\"\\nVocabulary saved to: {vocab_path}\")\n\n    if not data_file_3.exists():\n        raise FileNotFoundError(f\"Missing pairs source: {data_file_3}\")\n\nexcept Exception as e:\n    print(f\"\\nError: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T17:15:58.337095Z","iopub.execute_input":"2025-04-27T17:15:58.337288Z","iopub.status.idle":"2025-04-27T17:16:08.969714Z","shell.execute_reply.started":"2025-04-27T17:15:58.337271Z","shell.execute_reply":"2025-04-27T17:16:08.968829Z"}},"outputs":[{"name":"stdout","text":"=== Vocabulary Builder ===\nLoading data_file_1, data_file_2 and data_file_4...\nProcessing sentences for vocab...\n\nVocabulary built!\n Total tokens: 13,889,116\n Unique words: 128,973\n Top-5 frequent: [('stock', 391365), ('rt', 362726), ('spx', 180876), ('aapl', 124425), ('spy', 116542)]\n\nSample mappings:\n  'jpmorgan': 0\n  'reel': 1\n  'expectation': 2\n  'beyond': 3\n  'meat': 4\n  'nomura': 5\n  'point': 6\n  'booking': 7\n  'weakness': 8\n  'carnival': 9\n\nVocabulary saved to: /kaggle/working/checkpoints/vocabulary.json\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"print(\"\\nLoading data_file_3 and data_file_4 for training-pair generation...\")\ndata = load_json(data_file_3) + data4\n\ndef generate_training_data(data, window_size=10):\n    pairs = []\n    for entry in data:\n        sentence = entry[\"sentence\"]\n        sentence_length = len(sentence)\n        for i, center in enumerate(sentence):\n            if center not in word2idx:\n                continue\n            for j in range(max(0, i - window_size), min(sentence_length, i + window_size + 1)):\n                if i != j and sentence[j] in word2idx:\n                    pairs.append((word2idx[center], word2idx[sentence[j]]))\n    return pairs\n\ntraining_pairs = generate_training_data(data, window_size=5)\nprint(f\"Number of training pairs: {len(training_pairs)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T17:16:08.971501Z","iopub.execute_input":"2025-04-27T17:16:08.971767Z","iopub.status.idle":"2025-04-27T17:16:45.656124Z","shell.execute_reply.started":"2025-04-27T17:16:08.971737Z","shell.execute_reply":"2025-04-27T17:16:45.655309Z"}},"outputs":[{"name":"stdout","text":"\nLoading data_file_3 and data_file_4 for training-pair generation...\nNumber of training pairs: 106363598\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nimport os\n\ndef sigmoid(x):\n    return 1 / (1 + torch.exp(-torch.clamp(x, -10, 10)))\n\ndef normalize_rows(mat):\n    norm = torch.norm(mat, dim=1, keepdim=True)\n    return mat / (norm + 1e-8)\n\n# Setting device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Configurations\nembedding_dim = 300\nlearning_rate = 0.0008\nnegative_samples = 10\nbatch_size = 4096\n\n# Adam optimizer hyperparameters\nbeta1 = 0.9\nbeta2 = 0.999\neps = 1e-8\n\nCHECKPOINT_DIR = \"/kaggle/working/checkpoints\"\ncheckpoint_path = os.path.join(CHECKPOINT_DIR, \"model.pt\")\nos.makedirs(CHECKPOINT_DIR, exist_ok=True)\n\n# Early stopping\npatience = 3\nmin_delta = 1e-3\nbest_loss = float(\"inf\")\nepochs_without_improve = 0\n\n# Prepare training pairs\nif isinstance(training_pairs, list):\n    training_pairs = torch.tensor(training_pairs, dtype=torch.long)\nelif isinstance(training_pairs, torch.Tensor):\n    training_pairs = training_pairs.clone().detach().to(dtype=torch.long)\nelse:\n    raise ValueError(\"training_pairs must be either list or torch.Tensor\")\n\ntraining_pairs = training_pairs.to(device)\nvocab_size = len(word2idx)\n\n# Model Initialization\nstart_epoch = 0\n\nif os.path.exists(checkpoint_path):\n    try:\n        ckpt = torch.load(checkpoint_path, map_location=device, weights_only=True)\n    except:\n        ckpt = torch.load(checkpoint_path, map_location=device, weights_only=False)\n\n    W_in = ckpt[\"W_in\"].float().to(device)\n    W_out = ckpt[\"W_out\"].float().to(device)\n    start_epoch = int(ckpt[\"epoch\"])\n    m_in = ckpt[\"m_in\"].to(device)\n    v_in = ckpt[\"v_in\"].to(device)\n    m_out = ckpt[\"m_out\"].to(device)\n    v_out = ckpt[\"v_out\"].to(device)\n    t_step = int(ckpt[\"t_step\"])\n    print(f\"Resumed from epoch {start_epoch}\")\n\n    if torch.isnan(W_in).any() or torch.isnan(W_out).any():\n        print(\"Checkpoint contains NaNs â€” resetting weights.\")\n        W_in = torch.empty(vocab_size, embedding_dim, device=device)\n        W_out = torch.empty(embedding_dim, vocab_size, device=device)\n        torch.nn.init.xavier_uniform_(W_in)\n        torch.nn.init.xavier_uniform_(W_out)\n        start_epoch = 0\nelse:\n    print(\"No checkpoint found. Initializing weights using Xavier.\")\n    W_in = torch.empty(vocab_size, embedding_dim, device=device)\n    W_out = torch.empty(embedding_dim, vocab_size, device=device)\n    torch.nn.init.xavier_uniform_(W_in)\n    torch.nn.init.xavier_uniform_(W_out)\n    m_in = torch.zeros_like(W_in)\n    v_in = torch.zeros_like(W_in)\n    m_out = torch.zeros_like(W_out)\n    v_out = torch.zeros_like(W_out)\n    t_step = 0\n\n# Negative Sampling\nword_freq = torch.tensor([word_counts[idx2word[i]] for i in range(vocab_size)],\n                         dtype=torch.float64).to(device)\nunigram_dist = word_freq ** 0.75\nunigram_dist /= unigram_dist.sum()\n\ndef get_negative_samples(batch_size, K):\n    return torch.multinomial(unigram_dist, num_samples=K * batch_size,\n                              replacement=True).view(batch_size, K).to(device)\n\n# Training Loop\nema_loss = None\nema_decay = 0.95\nmax_grad_norm = 5.0 \n\n# Scheduler Settings\nscheduler_gamma = 0.5\nscheduler_step = 5\n\nwhile True: \n    epoch = start_epoch\n    start_epoch += 1 \n\n    perm = torch.randperm(len(training_pairs), device=device)\n    training_pairs = training_pairs[perm]\n\n    total_loss = 0.0\n    num_batches = 0\n\n    for i in range(0, len(training_pairs), batch_size):\n        t_step += 1\n        batch = training_pairs[i:i + batch_size]\n        center_idxs = batch[:, 0].long()\n        target_idxs = batch[:, 1].long()\n\n        # Forward pass\n        v_c = W_in[center_idxs]\n        u_o = W_out[:, target_idxs]\n\n        # Positive samples\n        score_pos = torch.sum(v_c * u_o.T, dim=1)\n        score_pos = torch.clamp(score_pos, -10, 10)\n        pred_pos = sigmoid(score_pos)\n\n        # Negative samples\n        neg_ids = get_negative_samples(len(center_idxs), negative_samples).long()\n        u_k = W_out[:, neg_ids.T].permute(2, 1, 0)\n        score_neg = torch.sum(v_c[:, None, :] * u_k, dim=2)\n        score_neg = torch.clamp(score_neg, -10, 10)\n        pred_neg = sigmoid(-score_neg)\n\n        # Loss calculation\n        pred_pos = torch.clamp(pred_pos, 1e-7, 1 - 1e-7)\n        pred_neg = torch.clamp(pred_neg, 1e-7, 1 - 1e-7)\n        loss = -torch.log(pred_pos).mean() - torch.log(pred_neg).mean()\n        total_loss += float(loss)\n        num_batches += 1\n\n        # EMA Loss\n        ema_loss = loss if ema_loss is None else ema_decay * ema_loss + (1 - ema_decay) * loss\n\n        # Gradients for W_in\n        grad_pos = (pred_pos - 1).unsqueeze(1) * u_o.T\n        grad_neg = (1 - pred_neg).unsqueeze(2) * u_k\n        grad_in = grad_pos + grad_neg.mean(dim=1)\n\n        # Gradient clipping\n        grad_in = torch.clamp(grad_in, -max_grad_norm, max_grad_norm)\n\n        # Adam update for W_in\n        m_in[center_idxs] = beta1 * m_in[center_idxs] + (1 - beta1) * grad_in\n        v_in[center_idxs] = beta2 * v_in[center_idxs] + (1 - beta2) * (grad_in ** 2)\n        m_hat = m_in[center_idxs] / (1 - beta1 ** t_step)\n        v_hat = v_in[center_idxs] / (1 - beta2 ** t_step)\n        W_in[center_idxs] -= learning_rate * m_hat / (torch.sqrt(v_hat) + eps)\n\n        # Gradients for W_out\n        update_W_out = torch.zeros_like(W_out)\n        update_W_out.scatter_add_(1, target_idxs.unsqueeze(0), (pred_pos - 1) * v_c.T)\n        for k in range(negative_samples):\n            update_W_out.scatter_add_(1, neg_ids[:, k].unsqueeze(0), grad_neg[:, k].transpose(0, 1))\n\n        updated_cols = torch.unique(torch.cat((target_idxs, neg_ids.flatten())))\n        m_out[:, updated_cols] = beta1 * m_out[:, updated_cols] + (1 - beta1) * update_W_out[:, updated_cols]\n        v_out[:, updated_cols] = beta2 * v_out[:, updated_cols] + (1 - beta2) * (update_W_out[:, updated_cols] ** 2)\n        m_hat_out = m_out[:, updated_cols] / (1 - beta1 ** t_step)\n        v_hat_out = v_out[:, updated_cols] / (1 - beta2 ** t_step)\n        W_out[:, updated_cols] -= learning_rate * m_hat_out / (torch.sqrt(v_hat_out) + eps)\n\n    # End of epoch\n    avg_loss = total_loss / num_batches\n    grad_norm = torch.norm(grad_in, dim=1).mean()\n    print(f\"Epoch {epoch+1}, Avg Loss (EMA): {ema_loss:.4f}, Batch Avg Loss: {avg_loss:.4f}, Grad Norm: {grad_norm:.4f}\")\n\n    # Save checkpoint\n    torch.save({\"W_in\": W_in,\"W_out\": W_out,\"m_in\": m_in,\"v_in\": v_in,\"m_out\": m_out,\"v_out\": v_out,\"t_step\": t_step,\"epoch\": epoch + 1}, checkpoint_path)\n\n    # Mild regularization\n    W_out = normalize_rows(W_out.T).T * 0.99 + W_out * 0.01\n\n    # Learning Rate Scheduler\n    if (epoch + 1) % scheduler_step == 0:\n        learning_rate *= scheduler_gamma\n        print(f\"Scheduler: Reducing learning rate to {learning_rate:.6f}\")\n    \n    # Early Stopping\n    if best_loss - avg_loss > min_delta:\n        best_loss = avg_loss\n        epochs_without_improve = 0\n    else:\n        epochs_without_improve += 1\n        print(f\"No improvement. {epochs_without_improve}/{patience} patience used.\")\n        if epochs_without_improve >= patience:\n            print(f\"Early stopping at epoch {epoch+1}. Best loss: {best_loss:.4f}\")\n            break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T17:18:49.791833Z","iopub.execute_input":"2025-04-27T17:18:49.792169Z","iopub.status.idle":"2025-04-27T18:53:24.522706Z","shell.execute_reply.started":"2025-04-27T17:18:49.792146Z","shell.execute_reply":"2025-04-27T18:53:24.521606Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nNo checkpoint found. Initializing weights using Xavier.\nEpoch 1, Avg Loss (EMA): 1.3359, Batch Avg Loss: 1.3493, Grad Norm: 0.0396\nEpoch 2, Avg Loss (EMA): 1.2792, Batch Avg Loss: 1.2967, Grad Norm: 0.2164\nEpoch 3, Avg Loss (EMA): 1.2305, Batch Avg Loss: 1.2465, Grad Norm: 0.3797\nEpoch 4, Avg Loss (EMA): 1.2214, Batch Avg Loss: 1.2241, Grad Norm: 0.3954\nEpoch 5, Avg Loss (EMA): 1.2187, Batch Avg Loss: 1.2188, Grad Norm: 0.3948\nScheduler: Reducing learning rate to 0.000400\nEpoch 6, Avg Loss (EMA): 1.2158, Batch Avg Loss: 1.2157, Grad Norm: 0.3937\nEpoch 7, Avg Loss (EMA): 1.2154, Batch Avg Loss: 1.2145, Grad Norm: 0.3934\nEpoch 8, Avg Loss (EMA): 1.2132, Batch Avg Loss: 1.2135, Grad Norm: 0.3907\nNo improvement. 1/3 patience used.\nEpoch 9, Avg Loss (EMA): 1.2134, Batch Avg Loss: 1.2127, Grad Norm: 0.3888\nEpoch 10, Avg Loss (EMA): 1.2122, Batch Avg Loss: 1.2121, Grad Norm: 0.3855\nScheduler: Reducing learning rate to 0.000200\nNo improvement. 1/3 patience used.\nEpoch 11, Avg Loss (EMA): 1.2126, Batch Avg Loss: 1.2112, Grad Norm: 0.3890\nEpoch 12, Avg Loss (EMA): 1.2112, Batch Avg Loss: 1.2108, Grad Norm: 0.3852\nNo improvement. 1/3 patience used.\nEpoch 13, Avg Loss (EMA): 1.2113, Batch Avg Loss: 1.2105, Grad Norm: 0.3860\nNo improvement. 2/3 patience used.\nEpoch 14, Avg Loss (EMA): 1.2107, Batch Avg Loss: 1.2103, Grad Norm: 0.3914\nNo improvement. 3/3 patience used.\nEarly stopping at epoch 14. Best loss: 1.2112\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nimport os\n\ndef save_full_w2v_model(W_in, word2idx, idx2word, checkpoint_dir=\"./checkpoints\"):\n    os.makedirs(checkpoint_dir, exist_ok=True)\n\n    try:\n        embeddings_path = os.path.join(checkpoint_dir, \"final_w2v_embeddings.npy\")\n        np.save(embeddings_path, W_in.cpu().numpy() if isinstance(W_in, torch.Tensor) else W_in)\n        vocab_path = os.path.join(checkpoint_dir, \"final_w2v_vocabulary.npz\")\n        np.savez_compressed(vocab_path, word2idx=word2idx, idx2word=idx2word)\n\n        print(f\"Full model saved to: {checkpoint_dir}\")\n        print(f\"  - Embeddings: {embeddings_path}\")\n        print(f\"  - Vocabulary: {vocab_path}\")\n        return True\n    except Exception as e:\n        print(f\"Failed to save model: {str(e)}\")\n        return False\n        \nsave_full_w2v_model(W_in, word2idx, idx2word)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:54:07.758730Z","iopub.execute_input":"2025-04-27T18:54:07.759601Z","iopub.status.idle":"2025-04-27T18:54:08.582069Z","shell.execute_reply.started":"2025-04-27T18:54:07.759565Z","shell.execute_reply":"2025-04-27T18:54:08.581200Z"}},"outputs":[{"name":"stdout","text":"Full model saved to: ./checkpoints\n  - Embeddings: ./checkpoints/final_w2v_embeddings.npy\n  - Vocabulary: ./checkpoints/final_w2v_vocabulary.npz\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"from gensim.models import FastText\nimport os\n\nsentences = [entry[\"sentence\"] for entry in data]\n\nfasttext_model = FastText(\n    vector_size=300,       \n    window=5,              \n    min_count=1,           \n    workers=4,             \n    sg=1,                  \n    epochs=20              \n)\n\nfasttext_model.build_vocab(sentences)\nfasttext_model.train(sentences, total_examples=len(sentences), epochs=fasttext_model.epochs)\n\nfasttext_embeddings = {word: fasttext_model.wv[word] for word in word2idx.keys() if word in fasttext_model.wv}\n\nsave_dir = \"./checkpoints\"\nos.makedirs(save_dir, exist_ok=True)\nfasttext_model.save(os.path.join(save_dir, \"fasttext.model\"))\n\nprint(f\"FastText training complete. Embeddings available for {len(fasttext_embeddings)} words.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:56:22.460319Z","iopub.execute_input":"2025-04-27T18:56:22.461142Z","iopub.status.idle":"2025-04-27T19:35:26.301282Z","shell.execute_reply.started":"2025-04-27T18:56:22.461117Z","shell.execute_reply":"2025-04-27T19:35:26.300280Z"}},"outputs":[{"name":"stdout","text":"FastText training complete. Embeddings available for 128973 words.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import numpy as np\nimport os\nimport torch\n\ndef save_hybrid_model(W_in, fasttext_model, word2idx, idx2word, checkpoint_dir=\"./checkpoints\"):\n    os.makedirs(checkpoint_dir, exist_ok=True)\n\n    try:\n        W_in_np = W_in.cpu().numpy() if isinstance(W_in, torch.Tensor) else W_in\n        \n        hybrid_embeddings = np.zeros_like(W_in_np)\n        missing_words = []\n        \n        for word, idx in word2idx.items():\n            if word in fasttext_model.wv:\n                hybrid_embeddings[idx] = 0.5 * (W_in_np[idx] + fasttext_model.wv[word])\n            else:\n                hybrid_embeddings[idx] = W_in_np[idx]\n                missing_words.append(word)\n\n        embeddings_path = os.path.join(checkpoint_dir, \"hybrid_embeddings.npy\")\n        np.save(embeddings_path, hybrid_embeddings)\n\n        vocab_path = os.path.join(checkpoint_dir, \"hybrid_vocabulary.npz\")\n        np.savez_compressed(vocab_path, word2idx=word2idx, idx2word=idx2word)\n\n        print(f\"Hybrid model saved to: {checkpoint_dir}\")\n        print(f\"  - Embeddings: {embeddings_path}\")\n        print(f\"  - Vocabulary: {vocab_path}\")\n        print(f\"  - Note: {len(missing_words)} words used original W2V (missing in FastText)\")\n        return True\n        \n    except Exception as e:\n        print(f\"Failed to save hybrid model: {str(e)}\")\n        return False\n\nsave_hybrid_model(W_in, fasttext_model, word2idx, idx2word)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:35:26.303166Z","iopub.execute_input":"2025-04-27T19:35:26.303820Z","iopub.status.idle":"2025-04-27T19:35:28.929392Z","shell.execute_reply.started":"2025-04-27T19:35:26.303788Z","shell.execute_reply":"2025-04-27T19:35:28.928476Z"}},"outputs":[{"name":"stdout","text":"Hybrid model saved to: ./checkpoints\n  - Embeddings: ./checkpoints/hybrid_embeddings.npy\n  - Vocabulary: ./checkpoints/hybrid_vocabulary.npz\n  - Note: 0 words used original W2V (missing in FastText)\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import numpy as np\nfrom scipy.sparse import dok_matrix, csr_matrix\n\ndef build_cooccurrence_matrix_sparse(training_pairs, vocab_size, verbose=True):\n    cooccur_dok = dok_matrix((vocab_size, vocab_size), dtype=np.float32)\n    \n    if hasattr(training_pairs, 'cpu'):\n        pairs = training_pairs.cpu().numpy()\n    else:\n        pairs = np.array(training_pairs, dtype=np.int32)\n\n    if verbose:\n        print(f\"Building sparse co-occurrence from {len(pairs):,} pairs...\")\n\n    for center, context in pairs:\n        if center < vocab_size and context < vocab_size:\n            cooccur_dok[center, context] += 1.0\n\n    cooccur_csr = cooccur_dok.tocsr()\n\n    cooccur_csr.data[:] = np.log1p(cooccur_csr.data)\n\n    if verbose:\n        nnz = cooccur_csr.count_nonzero()\n        total = vocab_size * vocab_size\n        print(f\"Sparse matrix built, shape={cooccur_csr.shape}, nnz={nnz:,} ({nnz/total:.2%})\")\n\n    return cooccur_csr\n\ncooccur = build_cooccurrence_matrix_sparse(training_pairs, vocab_size=len(word2idx))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:35:28.930290Z","iopub.execute_input":"2025-04-27T19:35:28.930604Z","iopub.status.idle":"2025-04-27T20:10:14.210424Z","shell.execute_reply.started":"2025-04-27T19:35:28.930577Z","shell.execute_reply":"2025-04-27T20:10:14.209584Z"}},"outputs":[{"name":"stdout","text":"Building sparse co-occurrence from 106,363,598 pairs...\nSparse matrix built, shape=(128973, 128973), nnz=12,776,411 (0.08%)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD\nimport torch\n\ndef enhance_embeddings_with_svd(cooccur, W_in, embedding_dim, weight_in=0.7, weight_glove=0.3):\n    try:\n        is_tensor = isinstance(W_in, torch.Tensor)\n        if is_tensor:\n            device = W_in.device\n            W_np = W_in.cpu().numpy()\n        else:\n            W_np = W_in\n\n        svd = TruncatedSVD(n_components=embedding_dim)\n        glove_components = svd.fit_transform(cooccur)\n\n        if glove_components.shape[0] != W_np.shape[0]:\n            raise ValueError(f\"Dimension mismatch: W_in has {W_np.shape[0]} rows, \"\n                           f\"but cooccur has {glove_components.shape[0]} rows\")\n\n        enhanced_np = weight_in * W_np + weight_glove * glove_components\n\n        if is_tensor:\n            enhanced_embeddings = torch.from_numpy(enhanced_np).to(device)\n        else:\n            enhanced_embeddings = enhanced_np\n\n        return enhanced_embeddings, glove_components\n\n    except Exception as e:\n        print(f\"Error in enhance_embeddings_with_svd: {str(e)}\")\n        raise\n\nenhanced_embeddings, glove_components = enhance_embeddings_with_svd(cooccur, W_in, embedding_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T20:10:14.211839Z","iopub.execute_input":"2025-04-27T20:10:14.212099Z","iopub.status.idle":"2025-04-27T20:11:00.112470Z","shell.execute_reply.started":"2025-04-27T20:10:14.212080Z","shell.execute_reply":"2025-04-27T20:11:00.111552Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import numpy as np\nfrom pathlib import Path\nimport torch\n\ndef save_glove_w2v_enhanced(enhanced_embeddings, word2idx, idx2word, model_name=\"glove_w2v_enhanced\", checkpoint_dir=\"./checkpoints\"):\n    try:\n        checkpoint_dir = Path(checkpoint_dir)\n        checkpoint_dir.mkdir(parents=True, exist_ok=True)\n\n        if isinstance(enhanced_embeddings, torch.Tensor):\n            enhanced_embeddings = enhanced_embeddings.cpu().numpy()\n        elif hasattr(enhanced_embeddings, '__cuda_array_interface__'):  # Handle CuPy arrays\n            import cupy as cp\n            enhanced_embeddings = cp.asnumpy(enhanced_embeddings)\n\n        embeddings_path = checkpoint_dir / f\"{model_name}_embeddings.npy\"\n        np.save(str(embeddings_path), enhanced_embeddings)\n\n        vocab_path = checkpoint_dir / f\"{model_name}_vocabulary.npz\"\n        np.savez_compressed(str(vocab_path), word2idx=word2idx, idx2word=idx2word)\n\n        print(f\"Enhanced model saved to: {checkpoint_dir}\")\n        print(f\"  - Embeddings: {embeddings_path}\")\n        print(f\"  - Vocabulary: {vocab_path}\")\n        return True\n\n    except Exception as e:\n        print(f\"Failed to save enhanced model: {str(e)}\")\n        return False\n\nsave_success = save_glove_w2v_enhanced(enhanced_embeddings=enhanced_embeddings, word2idx=word2idx, idx2word=idx2word, model_name=\"glove_w2v_enhanced\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T20:11:00.113536Z","iopub.execute_input":"2025-04-27T20:11:00.113823Z","iopub.status.idle":"2025-04-27T20:11:00.930140Z","shell.execute_reply.started":"2025-04-27T20:11:00.113803Z","shell.execute_reply":"2025-04-27T20:11:00.929368Z"}},"outputs":[{"name":"stdout","text":"Enhanced model saved to: checkpoints\n  - Embeddings: checkpoints/glove_w2v_enhanced_embeddings.npy\n  - Vocabulary: checkpoints/glove_w2v_enhanced_vocabulary.npz\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import numpy as np\nimport torch\n\ndef combine_embeddings(W_in, fasttext_model, glove_components, idx2word, weights=(0.5, 0.3, 0.2)):\n    try:\n        is_tensor = isinstance(W_in, torch.Tensor)\n        if is_tensor:\n            device = W_in.device\n            W_np = W_in.cpu().numpy()\n        else:\n            W_np = W_in\n\n        fasttext_vecs = []\n        missing_words = []\n        \n        for word in idx2word.values():\n            if word in fasttext_model.wv:\n                fasttext_vecs.append(fasttext_model.wv[word])\n            else:\n                fasttext_vecs.append(np.zeros(W_np.shape[1]))  \n                missing_words.append(word)\n                \n        fasttext_vecs = np.array(fasttext_vecs)\n        \n        if missing_words:\n            print(f\"Note: Used zero vectors for {len(missing_words)} words missing in FastText\")\n\n        if W_np.shape != fasttext_vecs.shape:\n            raise ValueError(f\"Shape mismatch: W_in {W_np.shape} vs FastText {fasttext_vecs.shape}\")\n        if W_np.shape[0] != glove_components.shape[0]:\n            raise ValueError(f\"Row count mismatch: W_in {W_np.shape[0]} vs GloVe {glove_components.shape[0]}\")\n\n        w1, w2, w3 = weights\n        combined_np = w1 * W_np + w2 * fasttext_vecs + w3 * glove_components\n\n        if is_tensor:\n            return torch.from_numpy(combined_np).to(device)\n        return combined_np\n\n    except Exception as e:\n        print(f\"Error combining embeddings: {str(e)}\")\n        raise\n\nfinal_embeddings = combine_embeddings(\n    W_in=W_in, \n    fasttext_model=fasttext_model,\n    glove_components=glove_components,\n    idx2word=idx2word,\n    weights=(0.5, 0.3, 0.2)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T20:11:00.931000Z","iopub.execute_input":"2025-04-27T20:11:00.931245Z","iopub.status.idle":"2025-04-27T20:11:02.111734Z","shell.execute_reply.started":"2025-04-27T20:11:00.931227Z","shell.execute_reply":"2025-04-27T20:11:02.110848Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import numpy as np\nfrom pathlib import Path\nimport torch\n\ndef save_combined_embeddings(final_embeddings, model_name=\"w2v_fasttext_glove_combined\", checkpoint_dir=\"./checkpoints\"):\n    try:\n        checkpoint_dir = Path(checkpoint_dir)\n        checkpoint_dir.mkdir(parents=True, exist_ok=True)\n\n        if isinstance(final_embeddings, torch.Tensor):\n            final_embeddings = final_embeddings.cpu().numpy()\n        elif hasattr(final_embeddings, '__cuda_array_interface__'):\n            import cupy as cp\n            final_embeddings = cp.asnumpy(final_embeddings)\n\n        embeddings_path = checkpoint_dir / f\"{model_name}_embeddings.npy\"\n        np.save(str(embeddings_path), final_embeddings)\n\n        print(f\"Combined embeddings saved to: {embeddings_path}\")\n        return True\n\n    except Exception as e:\n        print(f\"Failed to save combined embeddings: {str(e)}\")\n        return False\n\nsave_combined_embeddings(final_embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T20:11:02.112680Z","iopub.execute_input":"2025-04-27T20:11:02.112954Z","iopub.status.idle":"2025-04-27T20:11:02.391213Z","shell.execute_reply.started":"2025-04-27T20:11:02.112933Z","shell.execute_reply":"2025-04-27T20:11:02.390479Z"}},"outputs":[{"name":"stdout","text":"Combined embeddings saved to: checkpoints/w2v_fasttext_glove_combined_embeddings.npy\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# import shutil\n\n# src_dir = \"/kaggle/working/checkpoints\"\n# archive_name = \"/kaggle/working/checkpoints\"  \n\n# shutil.make_archive(archive_name, 'zip', src_dir)\n# print(\"Created archive at:\", archive_name + \".zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T20:12:34.552760Z","iopub.execute_input":"2025-04-27T20:12:34.553379Z","iopub.status.idle":"2025-04-27T20:15:58.059230Z","shell.execute_reply.started":"2025-04-27T20:12:34.553355Z","shell.execute_reply":"2025-04-27T20:15:58.058325Z"}},"outputs":[{"name":"stdout","text":"Created archive at: /kaggle/working/checkpoints.zip\n","output_type":"stream"}],"execution_count":17}]}